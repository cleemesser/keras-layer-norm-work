{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function, division, absolute_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.layers.LSTM as LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# modeled after ryankiros and gruln code\n",
    "def sample_normalize(x, _eps=1e-5):\n",
    "    \"\"\"centers a set of samples x to have zero mean and unit standard deviation\"\"\"\n",
    "    # keepdims=True the axes which are reduced are left in the result as dimensions with size one\n",
    "    # axis=-1 means do things across the last axis\n",
    "    m = K.mean(x, axis=-1, keepdims=True) # could subtract this off earlier\n",
    "    # std = K.std(x)\n",
    "    std = K.sqrt(K.var(x, axis=-1, keepdims=True) + _eps) # not using K.std for _eps stability\n",
    "    return (x-m)/ (std+_eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what the code for a single step of LSTM looks like in Keras \n",
    "(recurrent.py, the LSTM class function)\n",
    "\n",
    "```python \n",
    "    def step(self, x, states):\n",
    "        h_tm1 = states[0]\n",
    "        c_tm1 = states[1]\n",
    "        B_U = states[2]\n",
    "        B_W = states[3]\n",
    "\n",
    "        if self.consume_less == 'gpu':\n",
    "            z = K.dot(x * B_W[0], self.W) + K.dot(h_tm1 * B_U[0], self.U) + self.b\n",
    "\n",
    "            z0 = z[:, :self.output_dim]\n",
    "            z1 = z[:, self.output_dim: 2 * self.output_dim]\n",
    "            z2 = z[:, 2 * self.output_dim: 3 * self.output_dim]\n",
    "            z3 = z[:, 3 * self.output_dim:]\n",
    "\n",
    "            i = self.inner_activation(z0)\n",
    "            f = self.inner_activation(z1)\n",
    "            c = f * c_tm1 + i * self.activation(z2)\n",
    "            o = self.inner_activation(z3)\n",
    "        else:\n",
    "            if self.consume_less == 'cpu':\n",
    "                x_i = x[:, :self.output_dim]\n",
    "                x_f = x[:, self.output_dim: 2 * self.output_dim]\n",
    "                x_c = x[:, 2 * self.output_dim: 3 * self.output_dim]\n",
    "                x_o = x[:, 3 * self.output_dim:]\n",
    "            elif self.consume_less == 'mem':\n",
    "                x_i = K.dot(x * B_W[0], self.W_i) + self.b_i\n",
    "                x_f = K.dot(x * B_W[1], self.W_f) + self.b_f\n",
    "                x_c = K.dot(x * B_W[2], self.W_c) + self.b_c\n",
    "                x_o = K.dot(x * B_W[3], self.W_o) + self.b_o\n",
    "            else:\n",
    "                raise Exception('Unknown `consume_less` mode.')\n",
    "\n",
    "            i = self.inner_activation(x_i + K.dot(h_tm1 * B_U[0], self.U_i))\n",
    "            f = self.inner_activation(x_f + K.dot(h_tm1 * B_U[1], self.U_f))\n",
    "            c = f * c_tm1 + i * self.activation(x_c + K.dot(h_tm1 * B_U[2], self.U_c))\n",
    "            o = self.inner_activation(x_o + K.dot(h_tm1 * B_U[3], self.U_o))\n",
    "\n",
    "        h = o * self.activation(c)\n",
    "        return h, [h, c]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the _step function from ryankiros\n",
    "\n",
    "```python\n",
    "def ln(x, b, s):\n",
    "    _eps = 1e-5\n",
    "    output = (x - x.mean(1)[:,None]) / tensor.sqrt((x.var(1)[:,None] + _eps))\n",
    "    output = s[None, :] * output + b[None,:]\n",
    "    return output\n",
    "\n",
    "# class function for lstm layser normalization\n",
    "\n",
    "\n",
    "\n",
    "    def _step(mask, sbelow, sbefore, cell_before, *args):\n",
    "        sbelow_ = ln(sbelow, param('b1'), param('s1'))\n",
    "        sbefore_ = ln(dot(sbefore, param('U')), param('b2'), param('s2'))\n",
    "\n",
    "        preact = sbefore_ + sbelow_ + param('b')\n",
    "\n",
    "        i = Sigmoid(_slice(preact, 0, dim))\n",
    "        f = Sigmoid(_slice(preact, 1, dim))\n",
    "        o = Sigmoid(_slice(preact, 2, dim))\n",
    "        c = Tanh(_slice(preact, 3, dim))\n",
    "\n",
    "        c = f * cell_before + i * c\n",
    "        c = mask * c + (1. - mask) * cell_before\n",
    "\n",
    "        c_ = ln(c, param('b3'), param('s3'))\n",
    "        h = o * tensor.tanh(c_)\n",
    "        h = mask * h + (1. - mask) * sbefore\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LSTM-LN(LSTM):\n",
    "    def step(self, x, states):\n",
    "        h_tm1 = states[0]\n",
    "        c_tm1 = states[1]\n",
    "        B_U = states[2]\n",
    "        B_W = states[3]\n",
    "\n",
    "        if self.consume_less == 'gpu':\n",
    "            # original linear activity\n",
    "            # z = K.dot(x * B_W[0], self.W) + K.dot(h_tm1 * B_U[0], self.U) + self.b\n",
    "            # linear activity without bias term self.b # will need to add this back !!! (see what ryankiros does in ln())\n",
    "\n",
    "            z = K.dot(x * B_W[0], self.W) + K.dot(h_tm1 * B_U[0], self.U)\n",
    "            # seems that ryankiros divides things into inputs from below and recurrent input from before (t-1)\n",
    "            # and normalizes them \n",
    "            \n",
    "            z0 = z[:, :self.output_dim]                         # z0(x_i)         \n",
    "            z1 = z[:, self.output_dim: 2 * self.output_dim]     # z1(x_f)\n",
    "            z2 = z[:, 2 * self.output_dim: 3 * self.output_dim] # z2(x_c)\n",
    "            z3 = z[:, 3 * self.output_dim:]                     # z3(x_o)\n",
    "            # normalization\n",
    "            \n",
    "            i = self.inner_activation(z0)\n",
    "            f = self.inner_activation(z1)\n",
    "            c = f * c_tm1 + i * self.activation(z2)\n",
    "            o = self.inner_activation(z3)\n",
    "        else:\n",
    "            if self.consume_less == 'cpu':\n",
    "                x_i = x[:, :self.output_dim]\n",
    "                x_f = x[:, self.output_dim: 2 * self.output_dim]\n",
    "                x_c = x[:, 2 * self.output_dim: 3 * self.output_dim]\n",
    "                x_o = x[:, 3 * self.output_dim:]\n",
    "            elif self.consume_less == 'mem':\n",
    "                x_i = K.dot(x * B_W[0], self.W_i) + self.b_i\n",
    "                x_f = K.dot(x * B_W[1], self.W_f) + self.b_f\n",
    "                x_c = K.dot(x * B_W[2], self.W_c) + self.b_c\n",
    "                x_o = K.dot(x * B_W[3], self.W_o) + self.b_o\n",
    "            else:\n",
    "                raise Exception('Unknown `consume_less` mode.')\n",
    "\n",
    "            i = self.inner_activation(x_i + K.dot(h_tm1 * B_U[0], self.U_i))\n",
    "            f = self.inner_activation(x_f + K.dot(h_tm1 * B_U[1], self.U_f))\n",
    "            c = f * c_tm1 + i * self.activation(x_c + K.dot(h_tm1 * B_U[2], self.U_c))\n",
    "            o = self.inner_activation(x_o + K.dot(h_tm1 * B_U[3], self.U_o))\n",
    "\n",
    "        h = o * self.activation(c)\n",
    "        return h, [h, c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
